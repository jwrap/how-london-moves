{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data gathering and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is dedicated to data gathering and preprocessing. That is, with this notebook you'll be able to: download the data, unzip it (if necessary), and, finally, prepare the data for further vizualization and analysis.  \n",
    "\n",
    "In this study, we used open data from the following sources:\n",
    "1. London Datastore (London shape files);\n",
    "2. Office for National Statistics (London population);\n",
    "3. Transport for London (metro traffic);\n",
    "4. Wikimedia Commons (metro station locations);\n",
    "5. OpenStreetMaps (points of interest).\n",
    "\n",
    "The links to the data sets can be found in the References section.\n",
    "\n",
    "To gather the data we used URL links to the websites of the data providers. Note, that the __data sets can be updated__ by corresponding agencies. Therefore, some discrepancies are possible: new variables will become available, or some data set will have fewer attributes.\n",
    "\n",
    "The following figure describes data preprocessing pipeline:\n",
    "\n",
    "<img src=\"../figures/data-preprocessing-pipeline.png\" width=\"800\"/>\n",
    "\n",
    "The notebook is split into three sections: Data Gathering, Data Preprocessing and References. Each of the sections consists of subsections covering different data sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, zipfile, io, os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "from pyrosm import OSM\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__London shape files__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download date: 10-06-2020 23:53:21\n"
     ]
    }
   ],
   "source": [
    "url = 'https://data.london.gov.uk/download/statistical-gis-boundary-files-london/9ba8c833-6370-4b11-abdc-314aa020d5e0/statistical-gis-boundaries-london.zip'\n",
    "r = requests.get(url)\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "directory = \"../data/raw/geometry/\"\n",
    "if not os.path.exists(directory):\n",
    "    print(f'Succefully created new directory {directory}')\n",
    "    os.makedirs(directory)\n",
    "\n",
    "z.extractall(path=directory)\n",
    "print(f'Download date: {datetime.today().strftime(\"%d-%m-%Y %H:%M:%S\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__London population__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download date: 10-06-2020 23:53:24\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.ons.gov.uk/file?uri=%2fpeoplepopulationandcommunity%2fpopulationandmigration%2fpopulationestimates%2fdatasets%2fcensusoutputareaestimatesinthelondonregionofengland%2fmid2017/sape20dt10amid2017coaunformattedsyoaestimateslondon.zip'\n",
    "r = requests.get(url)\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "directory = \"../data/raw/population/\"\n",
    "if not os.path.exists(directory):\n",
    "    print(f'Succefully created new directory {directory}')\n",
    "    os.makedirs(directory)\n",
    "    \n",
    "z.extractall(path=directory)\n",
    "print(f'Download date: {datetime.today().strftime(\"%d-%m-%Y %H:%M:%S\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__OpenStreetMaps POIs__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download date: 10-06-2020 23:53:30\n",
      "Wall time: 5.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "url = 'https://download.geofabrik.de/europe/great-britain/england/greater-london-latest.osm.pbf'\n",
    "r = requests.get(url)\n",
    "\n",
    "directory = \"../data/raw/pois/\"\n",
    "if not os.path.exists(directory):\n",
    "    print(f'Succefully created new directory {directory}')\n",
    "    os.makedirs(directory)\n",
    "    \n",
    "with open(directory + 'greater-london-latest.osm.pbf', 'wb') as f:\n",
    "    f.write(r.content)\n",
    "print(f'Download date: {datetime.today().strftime(\"%d-%m-%Y %H:%M:%S\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Initialize the OSM parser object\n",
    "osm = OSM('../data/raw/pois/greater-london-latest.osm.pbf')\n",
    "\n",
    "# Let's read everything\n",
    "pois = osm.get_pois()\n",
    "\n",
    "# Gather info about POI type (combines the tag info from \"amenity\" and \"shop\")\n",
    "pois[\"poi_type\"] = pois[\"amenity\"]\n",
    "pois[\"poi_type\"] = pois[\"poi_type\"].fillna(pois[\"shop\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117549, 122)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pois.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../data/processed/pois/\"\n",
    "if not os.path.exists(directory):\n",
    "    print(f'Succefully created new directory {directory}')\n",
    "    os.makedirs(directory)\n",
    "    \n",
    "pois.to_csv(directory + \"pois.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Connect shape files and population__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Load population data\n",
    "population = pd.read_excel(\"../data/raw/population/SAPE20DT10a-mid-2017-coa-unformatted-syoa-estimates-london.xlsx\", \n",
    "                           sheet_name=\"Mid-2017 Persons\", skiprows=4)  # the first 4 rows have irrelevant information, so skip them\n",
    "\n",
    "# Rename a column\n",
    "population.rename({\"All Ages\": \"total_population\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Merge geometry and population data, both boroughs and subdistricts\n",
    "geometry = gpd.read_file('../data/raw/geometry/statistical-gis-boundaries-london/ESRI/OA_2011_London_gen_MHW.shp')\n",
    "merged = pd.merge(geometry, population[[\"OA11CD\", \"total_population\"]], on=\"OA11CD\")                            \n",
    "boroughs = merged.dissolve(\"LAD11NM\", aggfunc=\"sum\", as_index=False)                            \n",
    "subdistricts = merged.dissolve(\"WD11CD_BF\", aggfunc=\"sum\", as_index=False)\n",
    "\n",
    "# Define the directory to store the data\n",
    "directory = \"../data/processed/population/\"\n",
    "\n",
    "# Create it if needed\n",
    "if not os.path.exists(directory):\n",
    "    print(f'Succefully created new directory {directory}')\n",
    "    os.makedirs(directory)\n",
    "                \n",
    "# Save the data\n",
    "boroughs.to_file(directory + 'boroughs.json', driver='GeoJSON')\n",
    "subdistricts.to_file(directory + 'subdistricts.json', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__POIs__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117549, 122)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load POIs data\n",
    "pois = pd.read_csv(\"../data/processed/pois/pois.csv\", low_memory=False)\n",
    "pois = gpd.GeoDataFrame(pois, geometry=gpd.points_from_xy(pois['lon'], pois['lat']))\n",
    "pois.crs = {'init' : 'epsg=4326'}\n",
    "pois.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes geometry of a POI is of _Multipolygon_ or _Polygon_ type. Let's convert it to _Point_ type for uniformity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change geometry\n",
    "pois['geometry'] = pois['geometry'].apply(lambda x:x.centroid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In \"pois_categorization.csv\" we introduced a __subjective categorization__ of POIs into a set of categories. Let's assign these categories to the POIs that we've collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load categories and merge them with POIs data\n",
    "pois_categories = pd.read_csv(\"../data/external/pois_categories.csv\")\n",
    "pois = pd.merge(pois, pois_categories, left_on='poi_type', right_on=\"pois\")\n",
    "pois.drop('amenity', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove amenities tagged 'misc'\n",
    "pois = pois[pois['pois_category'] != \"misc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jryap\\Anaconda3\\envs\\primary\\lib\\site-packages\\pyproj\\crs\\crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Merge POIs with geometry\n",
    "resolution = 'boroughs'\n",
    "# resolution = 'boroughs'\n",
    "# Boroughs are tagged LAD11NM, subdistricts WD11CD_BF\n",
    "if resolution == 'subdistricts':\n",
    "    column_id = 'WD11CD_BF'\n",
    "elif resolution == 'boroughs':\n",
    "    column_id = 'LAD11NM'\n",
    "polygons = gpd.read_file(f'../data/processed/population/{resolution}.json')\n",
    "polygons.to_crs(epsg=4326, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jryap\\Anaconda3\\envs\\primary\\lib\\site-packages\\geopandas\\tools\\sjoin.py:61: UserWarning: CRS of frames being joined does not match!({'init': 'epsg=4326'} != {'init': 'epsg:4326', 'no_defs': True})\n",
      "  \"(%s != %s)\" % (left_df.crs, right_df.crs)\n"
     ]
    }
   ],
   "source": [
    "pois_in_polygon = gpd.sjoin(pois, polygons, how=\"inner\", op=\"intersects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get total counts of POIs types in each borough/subdistricts\n",
    "pois_counts = pois_in_polygon.groupby(['pois_category', f'{column_id}']).agg(len)\n",
    "pois_counts = pois_counts.reset_index()\n",
    "pois_counts = pois_counts.pivot(index=\"pois_category\", columns =f\"{column_id}\", values= \"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory to store the data\n",
    "directory = \"../data/processed/pois/\"\n",
    "\n",
    "# Create it if needed\n",
    "if not os.path.exists(directory):\n",
    "    print(f'Succefully created new directory {directory}')\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Save the data\n",
    "pois_counts.to_csv(directory + f'pois_counts_{resolution}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## 3. References\n",
    "1. London Datastore (2019). Statistical GIS Boundary Files for London. Retrieved from https://data.london.gov.uk/dataset/statistical-gis-boundary-files-london\n",
    "2. Office for National Statistics (2019). Census Output Area population estimates â€“ London, England (supporting information). Retrieved from https://www.ons.gov.uk/peoplepopulationandcommunity/populationandmigration/populationestimates/datasets/censusoutputareaestimatesinthelondonregionofengland\n",
    "3. Transport for London (2020). Transport for London API. Retrieved from https://api-portal.tfl.gov.uk/docs\n",
    "4. Wikimedia Commons (2020). London Underground geographic maps/CSV. Retrieved from https://commons.wikimedia.org/wiki/London_Underground_geographic_maps/CSV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
